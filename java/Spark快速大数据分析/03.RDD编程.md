# RDD 编程

## RDD 基础

* Spark 中的 RDD 就是一个不可变的分布式对象集合
    * 每个 RDD 都被分为多个分区，这些分区运行在不同的节点上
    * RDD 中可以包含 Python,Java,Scala 中任意类型的对象，以及用户自定义的对象

* 用户可以通过两种方式创建 RDD
    * 读取一个外部数据集
    * 在驱动程序里分发驱动器程序中的对象集合(list 或 set)

* RDD 操作分类
    * 代码实例
    ```python
    lines = sc.textFile("README.md")
    lines.first()
    ```
    * 以上 python 语句将会创建字符串 RDD。RDD支持两种操作
        * 转化操作: 由一个 RDD 生成一个新的 RDD
        * 行动操作: 对 RDD 计算出一个结果，并把结果返回到驱动器程序中，或者将其存储到外部存储中
    * 转化操作和行动操作的区别在于 Spark 计算 RDD 的方式不同
        * 我们可以在任何时刻定义 RDD ，但 Spark 只会惰性计算这些 RDD (即只有第一次在一个行动操作中用到时，才会真正计算它)
        * 默认情况下， Spark 的 RDD 会在每次对它们进行行动操作时重新计算。
            如果希望在多个行动操作中重用一个 RDD ，可以使用 `RDD.persist()` 让 Spark 把这个 RDD 缓存下来: 这种情况下，
            Spark 会把 RDD 的内容保存到内存中(以分区方式存储到集群的各个服务器上)，这样在之后就可以对它们进行重用；或者我们可以手动将其缓存到硬盘上

* 创建 RDD
    * Spark 提供了两种创建 RDD 的方式
        * 读取外部数据集
        ```python
        lines = sc.textFile( "/path/to/README.md" )
        ```
        * 直接对一个集合进行转化
        ```python
        lines = sc.parallelize( ["pandas","i like panda"] )
        ```

* RDD 操作
    * 转化操作: 返回一个新的 RDD 对象，如 map() 或 filter()
    ```python
    # 创建 RDD
    inputRDD = sc.textFile("log.txt")
    # 筛选 error 的行
    errorsRDD = inputRDD.filter(lambda x: "error" in x)
    # 筛选 warning 的行
    warningsRDD = inputRDD.filter(lambda x: "warning" in x)
    # 将 error 与 warning 的行进行合并
    badLinesRDD = errorsRDD.union(warningsRDD)
    ```
    * 行动操作: 向驱动器程序返回结果或者把结果写入外部系统的操作，会触发实际的计算，比如 count() 或 first()
    ```python
    # 计算一共有多少行 error 与 warning
    print badLinesRDD.count()
    # 通过 take 函数获取 RDD 中的少量元素，将其打印出来
    for line in badLinesRDD.take(10):
        print line
    # 将其序列化到文本文件中
    badLinesRDD.saveAsTextFile()
    ```

* 惰性求值
    * 惰性求值意味着当我们对 RDD 调用转化操作时，操作不会立刻执行。相反，Spark 会在内部记录下所要求执行的操作的相关信息。
        也就是说，我们不应该把 RDD 看做存储特定数据的数据集，而应该把每个 RDD 看做记录如何计算数据的指令表。
        把数据读取到 RDD 也是惰性的，因此当我们调用 sc.textFile() 时，并没有将数据读取进来，而只在必要时刻才会将其读取
    * 虽然转化操作是惰性的，但是我们可以通过调用一些命令，比如 rdd.count() 来强制其求值

* 向 Spark 传递函数
    * python 语法
    ```python
    # 直接使用 lambda 表达式
    word = rdd.filter( lambda s: 'error' in s )
    # 定义函数并传给 filter
    def containsError(s):
        retunr 'error' in s
    word = rdd.filter(containsError)
    ```
    * Java 语法
        * 函数需要作为实现了 Spark 的 org.apache.spark.api.java.function 包中的任一函数接口的对象来传递

|函数名|实现的方法|用途|
|:---|:---|:---|
| Function<T,R>         | R call(T)             | 接受一个输入值并返回一个输出，用于类似 map() 和 filter() 的操作中 |
| Function2<T1,T2,R>    | R call(T1,T2)         | 接受两个输入值并返回一个输出，用于类似 aggregate() 和 fold() 的操作中 |
| FlatMapFunction<T,R>  | Iterable<R> call(T)   | 接受一个输入值并返回任一多个输出，用于类似 flatMap() 这样的操作中 |

```java
// java 中使用匿名内部类进行函数传递
RDD<String> errors = lines.filter(new Function( String,Boolean ){
    public Boolean call(String x){
        return x.contains("error");
    }
})
// java 中使用具名类进行函数传递
class ContainsError implements Function( String,Boolean ){
    public Boolean call(String x){
        return x.contains("error");
    }
}
RDD<String> errors = lines.filter(new ContainsError());
// Java8 的 lambda 表达式
RDD<String> errors = lines.filter(s -> s.contains("error"));
```

## 常见的转化操作和行动操作

### 基本 RDD

* 针对各个元素的转化操作
    * 最常用的是 filter() map() flatMap()
        * filter: 接受一个函数，并将 RDD 中满足该函数的元素放回新的 RDD 中返回
        * map: 接受一个函数，把这个函数应用到 RDD 的每个元素，将函数的返回结果作为结果 RDD 中对应元素的值
        * flatMap: 接受一个函数，把这个函数应用到 RDD 的每个元素，将函数的返回结果集作为结果 RDD 中对应元素的值
    * 样例1 - map
    ```python
    # 求平方
    nums = sc.parallelize([1, 2, 3, 4])
    squared = nums.map(lambda x: x * x).collect()
    for num in squared:
    print "%i " % (num)
    ```
    * 样例2 - map 与 flatMap
    ```python
    # 单词切分
    lines = sc.parallelize(["hello world", "hi"])
    # 注意以下两行的区别
    ### 使用 flatMap ，则 RDD 中包含三个元素: 'hello' 'world' 'hi'
    words = lines.flatMap(lambda line: line.split(" "))
    ### 使用 map ，则 RDD 中包含两个元素: ['hello','world'] ['hi']
    words = lines.map(lambda line: line.split(" "))
    ```
    ```bash
    lines = sc.parallelize(["hello world", "hi"])
    >>> words = lines.flatMap(lambda line: line.split(" "))
    >>> words.collect()
    ['hello', 'world', 'hi']
    >>> words = lines.map(lambda line: line.split(" "))
    >>> words.collect()
    [['hello', 'world'], ['hi']]
    ```

* 伪集合操作
    * 尽管 RDD 本身不是严格意义上的集合，但是它也支持许多数学上的集合操作，比如合并和交的操作
        * distinct(): 去除 RDD 中的重复元素
        * union(otherRDD): 返回一个包含两个 RDD 中所有元素的 RDD
        * intersection(otherRDD): 只返回两个 RDD 中都有的元素，同时保证返回的 RDD 中不包含重复的元素
        * substract(otherRDD): 返回一个只存在于第一个 RDD 中而不存在于第二个 RDD 中的所有元素组成的 RDD
        * cartesian(otherRDD): 计算两个 RDD 的笛卡尔集
    * 注意，以上的 distinct,intersection,substract 操作特别耗费资源，因为它需要在所有 spark 节点上进行 shuffle，因此要慎用

* 汇总总结1 -- 对一个数据为 {1,2,3,3} 的 RDD 进行基本RDD转换操作

|函数名|实例|结果|目的|
|:---|:---|:---|:---|
| map()                                     | rdd.map(  x => x+1)       | {2,3,4,4}             | 将函数应用于 RDD 中的每个元素,将返回值构成新的 RDD |
| flatMap()                                 | rdd.flatMap(x => x.to(3)) | {1, 2, 3, 2, 3, 3, 3} | 将函数应用于 RDD 中的每个元素,将返回的迭代器的所有内容构成新的 RDD。通常用来切分单词 |
| filter()                                  | rdd.filter(x => x != 1)   | {2,3,3}               | 返回一个由通过传给 filter() 的函数的元素组成的 RDD |
| distinct()                                | rdd.distinct()            | {1,2,3}               | 去重 |
| sample(withReplacement, fraction, [seed]) | rdd.sample(false, 0.5)    | 非确定的               | 对 RDD 采样,以及是否替换 |

* 汇总总结2 -- 对数据分别为 {1,2,3} 和 {3,4,5} 的RDD进行针对两个RDD的转化操作

|函数名|实例|结果|目的|
|:---|:---|:---|:---|
| union()        | rdd.union(other)        | {1,2,3,3,4,5}           | 生成一个包含两个 RDD 中所有元素的 RDD |
| intersection() | rdd.intersection(other) | {3}                     | 求两个 RDD 共同的元素的 RDD |
| substract()    | rdd.subtract(other)     | {1,2}                   | 移除一个 RDD 中的内容(例如移除训练数据) |
| cartesian()    | rdd.cartesian(other)    | {(1,3), (1,4),...(3,5)} | 与另一个 RDD 的笛卡儿积 |

* 行动操作
    * 常用的行动操作
        * reduce(): 接受一个函数作为参数，该函数负责操作两个 RDD 元素类型的数据，然后返回同一类型的数据
        * fold(): 接受一个与 reduce 接受的函数签名相同的函数，再加上一个“初始值”来作为每个分区第一次调用时的结果。
            提供的初始值应当是你提供的操作的单位元素；即使用你的函数对这个初始值进行多次计算不会改变结果
        * aggregate(): 接受三个参数( 基础值,,转换函数 )
    * 容易迷惑的 reduce,fold,aggregate: [http://www.jianshu.com/p/15739e95a46e](http://www.jianshu.com/p/15739e95a46e)
    * 样例1 - reduce
    ```python
    sum = rdd.reduce( lambda x,y : x + y )
    ```
    ```java
    Integer sum = rdd.reduce(new Function2<Integer, Integer, Integer>() {
        public Integer call(Integer x, Integer y) { return x + y; }
    });
    ```
    * 样例2 - fold
    * 样例 - aggregate
    ```python
    def seqOp(x,y):
        print 'seq',x,y
        return ( x[0]*y,x[1]+1 )
    def comOp(x,y):
        return x,y
    print sc.parallelize([1, 2, 3, 4]).aggregate( (1,0),seqOp,comOp )
    ```



