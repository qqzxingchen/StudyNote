# 其他常用函数



## SparkContext.addFile(path) SparkFiles.get(Filename)

* 通过 `SparkContext.addFile(path)` ，可以构建一个文件列表，让每个工作节点在 Spark 作业中下载列表中的文件。
    这些文件可以来自驱动器的本地文件系统(如前面几个例子中所示范的那样)，或者来自 HDFS 或其他 Hadoop 所支持的文件系统，又或者是 HTTP、HTTPS 或 FTP 的 URI地址。
    当作业中的行动操作被触发时，这些文件就会被各节点下载，然后我们就可以在工作节点上通过 `SparkFiles.getRootDirectory` 找到它们。
    我们也可以使用 `SparkFiles.get(Filename)`来定位单个文件。

* 所有通过 SparkContext.addFile(path) 添加的文件都存储在同一个目录中，所以有必要使用唯一的名字。
