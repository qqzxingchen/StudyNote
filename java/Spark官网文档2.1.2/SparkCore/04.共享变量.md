# 共享变量

* 正常情况下，当一个函数提交到 spark 执行时，函数内部使用的所有变量都是原变量的独立拷贝。
    这些变量将会被拷贝到 spark 的每个节点上，但不会在节点之间进行同步更新；各节点上的任务执行完毕之后也不会再提交回驱动程序中。

* 由于支持通用的，可读写的共享变量将会比较低效，因此 spark 只为两种常见的使用模式提供了两种有限类型的共享变量:
    * 广播变量
    * 累加器

## 广播变量

* 广播变量可以让程序高效地向所有工作节点发送一个较大的只读值，以供一个或多个 Spark 操作使用。
    比如，如果应用需要向所有节点发送一个较大的只读查询表，甚至是机器学习算法中的一个很大的特征向量，广播变量用起来都很顺手。

* 我们可以通过 `v_broadcast = SparkContext.broadcast(v)` 来构建一个基于 `v` 的广播变量，然后在提交到各个不同节点上的函数中使用 `v_broadcast.value` 来获取 `v` 的值
    * 注意，如果在 `v_broadcast = SparkContext.broadcast(v)` 之后修改了 `v` 的值，则服务器节点上获取到的 `v_broadcast.value` 不会发生任何变化，因为该值只会发送一次

```python
v = [1,3,4]
counter = sc.broadcast( v )

def mapper(x):
    print 'counter',counter.value
    print 'v',v
    return x

sc.parallelize(range(3)).map(mapper).collect()
```

```bash
counter [1, 3, 4]
v [1, 3, 4]
counter [1, 3, 4]
v [1, 3, 4]
counter [1, 3, 4]
v [1, 3, 4]
```

## 累加器

* 累加器只支持加操作，且保证在各个不同节点之间的加操作最终可以回溯到驱动节点上

```python

accum = sc.accumulator(0)
sc.parallelize( range(100) ).foreach(lambda x: accum.add(x))
print 'accum', accum
```

```bash
accum 4950
```

* 注意，如果累加器只在转换操作的函数中使用（更新值），那么在代码中，在调用 rdd 的行动操作之前，累加器的值都不会发生任何变化。
    即，累加器值的更新也是 lazy 的

* 上述操作只支持语言中的 int 内建类型，我们可以通过继承 `AccumulatorParam` 类（python）来实现自己的累加器

```python
from pyspark import AccumulatorParam
class VectorAccumulatorParam(AccumulatorParam):
    def zero(self, initialValue):
        print 'initialValue',initialValue
        return initialValue

    # 注意，如果自定义累加器时，发现根据业务需求 zero 接口返回的数据的类型与 rdd 中各元素的数据类型不同，
    #       那么在 addInPlace 接口中就需要分开进行处理
    # 如 zero 接口返回的数据类型是 [] (数组)，rdd 中各个元素的数据类型是 int (整形)，
    #       然后要实现一个可以获取到 rdd 中所有元素的累加器(类似于 collect())
    # 那么可以按照下面的方式进行实现:
    def addInPlace(self, v1, v2):
        # 由于 addInPlace 函数的执行也分为两个阶段: 分区内数据聚合以及分区间数据聚合
        # 而这两个阶段的输入参数是不同的
        #       各个分区内聚合: v1([]) v2(int)
        #       分区间聚合: v1([]) v2([])
        # 因此需要通过 type(v2) 来判断是那个阶段
        # 另外，注意 zero() 返回的值，也会被多次使用
        #       各个分区内聚合: 分区内第一次聚合时， v1(zero 接口的返回值) v2(rdd 中当前分区的第一个元素)
        #       分区间聚合: 分区间第一次聚合时， v1(zero 接口的返回值) v2(rdd 第一个分区的聚合结果)
        if type(v2) == type([]):
            v1 += v2
        else:
            v1.append(v2)
        return v1

vecAccum = sc.accumulator(['zeroValue'], VectorAccumulatorParam())
sc.parallelize( range(100),5 ).foreach(lambda x: vecAccum.add(x))
print vecAccum
```

```bash
initialValue ['zeroValue']
[
    'zeroValue',
    'zeroValue', 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
    'zeroValue', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
    'zeroValue', 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
    'zeroValue', 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    'zeroValue', 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99
]
```
