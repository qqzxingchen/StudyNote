# RDD 持久化

* 默认情况下，spark的每次行动操作，都会重新计算该行动操作的所有前置转换操作，这对于实时变化的数据源很有用；
    但是对于不变的数据源（一定时间内不变），它将会把多个 rdd 重新计算多遍，影响程序的执行效率。
    因此我们可以将中间节点的 rdd 持久化，以便在以后的行为操作执行时，不会再次计算该 rdd 的值

* 可以通过 `rdd.persist()` 或者 `rdd.cache()` 来将 rdd 持久化。一旦该 rdd 因为某个行动操作而进行计算，则该 rdd 的值将会被缓存起。
    * spark 的缓存是容错的，如果 rdd 的任何分区丢失，则它将会自动重新计算该 rdd 的值

* rdd 的持久化包含不同的存储级别，如下

| 存储级别 | 描述 |
|:----|:----|
| MEMORY_ONLY                           | 默认级别，将 rdd 直接以对象的形式存储到 jvm 中。如果内存不够，某些分区将不会被缓存，因此每次需要时都会重新计算 |
| MEMORY_ONLY_SER(Java and Scala)       | 相比于 MEMORY_ONLY，只是将 rdd 序列化之后再进行存储 |
| MEMORY_AND_DISK                       | 将 rdd 直接以对象的形式存储到 jvm 中。如果内存不够，则这部分内容将会被写到磁盘中，使用的时候从磁盘中读取 |
| MEMORY_AND_DISK_SER(Java and Scala)   | 相比于 MEMORY_AND_DISK，只是将 rdd 序列化之后再进行存储 |
| DISK_ONLY                             | 将 rdd 直接以对象的形式存储到磁盘中，且只会存储到磁盘中 |
| OFF_HEAP(experimental)                | 堆外缓存，实验性功能 |

* 注意
    * 在 python 中，保存的对象将会总是使用 pickle 进行序列化，因此不关心选择的序列化级别

## rdd 持久化等级的选择

* spark 的存储级别是在内存使用以及 cpu 资源之间的不断折中
    * 如果 rdd 适合默认的存储级别( MEMORY_ONLY )，那就就用它，它是 cpu 使用效率最高的选项
    * 如果不适合默认存储级别，可以尝试使用 MEMORY_ONLY_SER 并选择一个快速序列化库来使对象更加节省空间，且访问速度仍旧比较快
    * 除非重新计算分区的速度与从磁盘上读取的速度一样慢，否则比建议将 rdd 序列化到磁盘上

## 持久化数据的移除

* spark 自动管理持久化数据在各个节点上的存储情况，并依据 LRU(least-recently-used) 算法移除旧的数据分区。
    当然，我们也可以通过调用 `rdd.unpersist()` 来手动移除持久化的数据



