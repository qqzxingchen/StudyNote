
# ES 是一个高度可扩展的开源全文本搜索以及分析引擎。
* 它支持大量数据的快速存储、搜索、分析

### 基本概念
* Near RealTime(NRT)
    * ES是一个近实时搜索平台，这意味着在你插入数据到该数据可被检索之间，只存在轻微的延迟（1s左右）

* Cluster 集群
    * 集群是一个或者多个存储数据的节点的集合，且提供所有这些节点之间的联合索引和搜索功能
    * 集群通过一个唯一的名字来标识，默认是 elasticsearch 。因此尽量不要在不同环境中重用相同的集群名称，防止将节点加入到错误的集群中

* Node 节点
    * 节点是集群的一部分，作为一个单独的服务器，它用来实际存储数据、并参与集群的索引和搜索功能
    * 默认情况下每个节点都会被一个Marvel生成的随机字符串所标识；当然也可以自己配置它
    * 节点可以加入到一个特定的集群中；默认情况下，在相同网络环境中，所有可以互相访问的节点都会加入到 elasticsearch 集群中

* Index 索引
    * 一个索引是一系列具有类似特性的文档的集合
    * 一个索引具有一个名称（字符串，且要求全部是小写字母），在进行索引、搜索、更新、删除操作时，将会通过该名称与相应的索引关联起来
    * 在一个集群中，可以定义任意多数量的索引

* Type 类型
    * 在一个索引中，可以定义一个或者多个类型。
    * 一个类型是某索引的一个逻辑 类别/分区，其中的语义完全取决于定义的人
    * 一般来所，会为具有一组公共字段的文档定义类型。

* Document 文档
    * 一个文档是一个可以被索引的信息的基本单元，使用 JSON 来表达
    * 在一个 index/type 中，可以存储任意多的文档
    * 注意，一个文档物理上将会驻留在索引中，但是逻辑上该文档应该归属于某索引的某个类型

* Shards & Replicas 切片、副本
    * 一个索引可以存储超过单节点硬盘限制的大量数据；但是实际上，如果单节点存储过多的数据，将会导致处理搜索请求过慢的问题
        * 为了解决该问题，ES提供了细分索引到多个切片的功能。
        * 在创建一个索引的时候，可以很容易地定义切片的数量，每一个切片对于它自身来说，都是一个全功能且独立的 "索引" ，它们可以被存储到不同的节点上
    * 切片的好处
        * 它允许水平分割/缩放内容卷
        * 它允许跨分片（可能在多个节点上）分布和并行化操作，从而提高性能/吞吐量
    * 切片如何分布以及如何将切片聚合回归的问题，将会由ES全权管理，对用户是透明的
    * 而在随时可能出现故障的 网络/云 环境中，为了避免因为单点故障，故障转移机制是非常有必要。为此，ES允许将索引的切片的一个或多个副本转换为副本切片
    * 副本的好处
        * 提供单节点故障的高可用机制；由此切片的副本不能与切片的源本分配到一个节点上
        * 它允许扩展搜索量/吞吐量，因为搜索可以并行地在所有副本上执行
    * 总结
        * 一个索引可以被分切成多个切片，一个索引也可以拥有0或多个副本
        * 一旦被副本，每个索引将会有主切片以及副本切片
        * 在索引创建时，可以定义切片的数量以及副本的数量；但是在索引创建之后，用户只能动态修改副本的数量而无法修改切片的数量
        * 默认情况下，每一个索引都分配了5个切片和1个副本（该索引一共有 5+5 = 10 个切片）

### 依赖
* ES要求至少是Java7。特别地对于写操作，它要求使用 JDK 1.8.0_73

### REST API功能简述
* ES 提供了 REST API 来访问集群，可以用来做以下事情
    * 检查集群、节点、索引是否健康、状态以及统计信息
    * 管理集群、节点、索引数据以及元数据
    * 索引之上的CRUD操作以及搜索操作
    * 执行扩展的搜索操作，比如分页、排序、筛选、聚合等其他操作

### 集群的健康信息、索引的基本信息查看 ( _cat API )

* 查看集群概览信息
    ```
    $ curl '127.0.0.1:19200/_cat/health?v'    
    epoch      timestamp cluster    status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
    1486542359 16:25:59  xc-es-test yellow          1         1      2   2    0    0        2             0                  -                 50.0%
    ```
    * 任何时候，集群的 status 都只会是: green yellow green
        * green     一切正常（集群可以正常提供功能）
        * yellow    所有数据都可用但是一些副本尚未创建成功（集群可以正常提供功能）
        * red       一些数据不可用（即使状态是 red，集群也可以只在可用的数据上提供搜索功能）

* 查看节点概览信息
    ```
    $ curl '127.0.0.1:19200/_cat/nodes?v'
    host      ip        heap.percent ram.percent load node.role master name
    10.0.2.15 10.0.2.15            8          98 0.00 d         *      Mad Jim Jaspers
    ```

* 查看索引
    ```
    $ curl '127.0.0.1:19200/_cat/indices?v'
    health status index                   pri rep docs.count docs.deleted store.size pri.store.size
    yellow open   .marvel-es-data-1         1   1          3            1      8.1kb          8.1kb
    yellow open   .marvel-es-1-2017.02.08   1   1        817            8    425.8kb        425.8kb
    ```
* 创建名为 customer 的索引
    ```
    $ curl -XPUT 'localhost:9200/customer'
    {
        "acknowledged" : true
    }
    $ curl '127.0.0.1:19200/_cat/indices?v'
    health status index                   pri rep docs.count docs.deleted store.size pri.store.size
    yellow open   customer                  5   1          0            0       650b           650b
    yellow open   .marvel-es-data-1         1   1          3            1      8.1kb          8.1kb
    yellow open   .marvel-es-1-2017.02.08   1   1        986           28    477.3kb        477.3kb
    ```
    * 之所以所有索引的 health 都是yellow，是因为该索引配置了1个副本，但是该副本却没有生成（ES不会将切片的副本以及切片的源本放到一个节点上，因此单节点时，health必为yellow）

* 删除某索引
    ```
    $ curl -XDELETE 'localhost:19200/customer?pretty'
    {
        "acknowledged" : true
    }
    ```

### 索引内文档的相关操作

* 查看详细信息
    ```
    $ curl -X<REST Verb> <Node>:<Port>/<Index>/<Type>/<ID>
    ```
    * 从API的格式上也可以看出来，某文档必然属于某索引的某类型

* 为索引插入数据
    ```
    # 为索引 customer 插入一个json: {'name':'John Doe'}，并指定id为1
    $ curl -XPUT 'localhost:19200/customer/external/1?pretty' -d '{"name": "John Doe"}'
    {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "1",
        "_version" : 1,
        "_shards" : {
            "total" : 2,
            "successful" : 1,
            "failed" : 0
        },
        "created" : true
    }

    # 为索引 customer 插入一个json: {'name':'John Doe'}，不指定ID，由ES自动随机生成该ID（ES确实是随机生成的，而不是自增的）
    # 注意这里的 POST 与上面的 PUT 的区别
    #   在REST API中，POST是指新建一条记录，PUT是指更新一条记录；如果指定了是某ID，通常是更新操作，用PUT；如果没有指定，通常是插入操作，用POST
    $ curl -XPOST 'localhost:19200/customer/external?pretty' -d '{"name": "John Doe"}'
    {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "1",
        "_version" : 1,
        "_shards" : {
            "total" : 2,
            "successful" : 1,
            "failed" : 0
        },
        "created" : true
    }
    ```

* 修改某文档1
    * 可以通过对某ID进行多次PUTJSON对象的方式，更新文档
    ```
    $ curl -XPUT 'localhost:19200/customer/external/1?pretty' -d '{"test":1}'
    {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "1",
        "_version" : 1,
        "_shards" : {
            "total" : 2,
            "successful" : 1,
            "failed" : 0
        },
        "created" : true                # 本次操作是创建
    }
    $ curl -XPUT 'localhost:19200/customer/external/1?pretty' -d '{"test":2}'
    {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "1",
        "_version" : 2,
        "_shards" : {
            "total" : 2,
            "successful" : 1,
            "failed" : 0
        },
        "created" : false               # 本次操作是修改
    }
    ```
    * 上面的操作方法，执行的是替换操作。即ES后台将会把原来的JSON数据删除掉，然后再设置新的JSON数据

* 修改某文档2 （_update方式）
    ```
    $ curl -XDELETE 'localhost:19200/customer'
    $ curl -XPUT  'localhost:19200/customer/external/1?pretty' -d '{"test": "test"}'
    $ curl -XPOST 'localhost:19200/customer/external/1/_update?pretty' -d '{"doc":{"test1": "test1"}}'
    $ curl -XPOST 'localhost:19200/customer/external/1/_update?pretty' -d '{"doc":{"test2": "test2"}}'
    $ curl -XGET  'localhost:19200/customer/external/1?pretty'
    {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "1",
        "_version" : 3,
        "found" : true,
        "_source" : {
            "test" : "test",
            "test1" : "test1",
            "test2" : "test2"
        }
    }
    ```
    * 这种方式不同于上面的修改方法，它执行的是合并操作。即ES后台将会把原来的JSON数据和提供的JSON数据进行合并，然后保存
    * 这种修改方式要求ID对应的Document已经存在。
    * doc 字段：使用这种方法进行更新的时候，需要把提供的JSON对象使用 "doc" 包住

* 删除某索引中的文档
    ```
    $ curl -XDELETE 'localhost:19200/customer/external/1?pretty'
    ```

* 查看某索引中的某条文档
    ```
    $ curl -XGET 'localhost:19200/customer/external/1?pretty'
    {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "1",
        "_version" : 1,
        "found" : true,
        "_source" : {
            "name" : "John Doe"
        }
    }
    ```

### 批处理 ( _bluk API )
* _bulk API 将会依次执行所有的命令；如果其中某些命令失败，_bulk 将不会停止，而是等所有都命令都执行完毕之后，统一返回所有命令的执行情况
    ```
    # 例子1
    $ curl -XPOST 'localhost:19200/customer/external/_bulk?pretty' -d '
        {"index":{"_id":"1"}}
        {"name": "John Doe" }
        {"index":{"_id":"2"}}
        {"name": "Jane Doe" }
    '
    # 以上的操作相当于是:
    $ curl -XPOST 'localhost:19200/customer/external/1?pretty' -d '{"name": "John Doe" }'
    $ curl -XPOST 'localhost:19200/customer/external/2?pretty' -d '{"name": "Jane Doe" }'

    # 例子2
    $ curl -XPOST 'localhost:9200/customer/external/_bulk?pretty' -d '
        {"update":{"_id":"1"}}
        {"doc": { "name": "John Doe becomes Jane Doe" } }
        {"delete":{"_id":"2"}}
    '
    # 以上的操作相当于是:
    $ curl -XPOST 'localhost:19200/customer/external/1/_update?pretty' -d '{"doc": { "name": "John Doe becomes Jane Doe" } }'
    $ curl -XDELETE 'localhost:19200/customer/external/2'
    ```

### 加载文件
* 加载文件内的数据到ES
    * 加载文件内大批量数据到ES，其本质是通过 _bluk API 来把文件内的内容推送到ES，因此json文件的内容需要符合 _bluk API 的要求
    ```
    ##### accounts.json
    {"index":{"_id":"1"}}
    {"account_number":1,"balance":39225,"firstname":"Amber","lastname":"Duke","age":32,"gender":"M","address":"880 Holmes Lane","employer":"Pyrami","email":"amberduke@pyrami.com","city":"Brogan","state":"IL"}
    {"index":{"_id":"6"}}
    {"account_number":6,"balance":5686,"firstname":"Hattie","lastname":"Bond","age":36,"gender":"M","address":"671 Bristol Street","employer":"Netagy","email":"hattiebond@netagy.com","city":"Dante","state":"TN"}
    {"index":{"_id":"13"}}
    {"account_number":13,"balance":32838,"firstname":"Nanette","lastname":"Bates","age":28,"gender":"F","address":"789 Madison Street","employer":"Quility","email":"nanettebates@quility.com","city":"Nogal","state":"VA"}
    ...
    ##### 命令行
    $ curl -XPOST 'localhost:19200/bank/account/_bulk?pretty' --data-binary "@accounts.json"
    ```
    * 注意这里的 -d 与 --data-binary 的区别，以及使用 --data-binary 时后面跟随的文件名前面需要添加 @

### Search API

* 需要注意的是，一旦你的搜索完成，则该查询已经完全完成；而不像是其他 SQL，返回一个结果集，可以一次加载部分数据
    * 即一旦 ES 查询结束，则将会把所有查询结果全量返回

* 对ES内容进行查询时，有两种方法
    * REST request URI
    * REST request body
        * 由于 request body 拥有更强大的表达功能，并且更易读取，因此下面只是对 request URI 提供一个简单的例子，实际情况中 request body 用的更多
    
* request URI
    ```
    # 格式
    curl 'localhost:19200/bank/_search?q=*&pretty'      # q=* 代表了返回所有记录
    {
        "took" : 2,
        "timed_out" : false,
        "_shards" : {
            "total" : 5,
            "successful" : 5,
            "failed" : 0
        },
        "hits" : {
            "total" : 1000,
            "max_score" : 1.0,
            "hits" : [ {
            "_index" : "bank",
            "_type" : "account",
            "_id" : "25",
            "_score" : 1.0,
            "_source" : {
                "account_number" : 25,
                "balance" : 40540,
                "firstname" : "Virginia",
                "lastname" : "Ayala",
                "age" : 39,
                "gender" : "F",
                "address" : "171 Putnam Avenue",
                "employer" : "Filodyne",
                "email" : "virginiaayala@filodyne.com",
                "city" : "Nicholson",
                "state" : "PA"
            }
            }, xxx ]
        }
    }
    ```
    * 其返回的JSON对象，包含以下部分：
        * took              ES执行查询操作所使用的毫秒数
        * timed_out         ES执行查询是否超时
        * _shards           ES执行查询时，访问了多少个 shard ，以及成功与失败查询的切片
        * hits              查询结果
        * hits.total        所有满足查询条件的文档的个数
        * hits.hits         查询结果
        * _score            当前文档与搜索条件的关联程度，值越大，代表关联性越大
        * max_score         当前搜索结果的文档集合中最大的 _score

* request body
    * 下面是与上面具有完全相同功能的 request body 实现
    ```
    $ curl -XPOST 'localhost:9200/bank/_search?pretty' -d '
    {
        "query": { "match_all": {} }
    }'
    ```

* 查询语言 - 基础查询
    * 关键字：size、from、sort
    ```
    # 查询所有文档并返回
    {
        "query":{ "match_all":{} } 
    }
    # 查询所有文档，但是只返回第一个文档
    {
        "query":{ "match_all":{} },
        "size": 1                   # 这里的 size 如果没有指定，则默认为10
    }
    # 查询所有文档，并返回第 11 个到第 20 个文档
    {
        "query":{ "match_all":{} } ,
        "size": 10,
        "from": 10                  # 这里的 from 如果没有指定，则默认为 0
    }
    # 查询所有文档，并按照 balance 的降序排列返回
    {
        "query":{ "match_all":{} },
        "sort":{ "balance":{ "order":"desc" } }
    }
    ```
* 查询语言进阶1 - match query
    * 关键字：match、match_phrase
    ```
    # 不返回文档的完整数据，而只是返回部分字段的数据，类似于SQL的 SELECT account_number,balance FROM table
    {
        "query":{ "match_all":{} },
        "_source":["account_number","balance"]
    }
    # 返回特定字段为特定值的文档，类似于 SQL 的 select * from table where account_number = 20
    {
        "query":{ "match":{ "account_number":20 } }
    }
    # 注意，下面几个例子中的 短语 的含义于 字符串 的含义有较大差别
    # ES会把待搜索的数据拆分成单词序列word_list（ 如 '198 Mill Lane' 会被拆分成 ['198','Mill','Lane'] ）
    # 然后把match的搜索条件也会拆分成单词序列search_list（拆分过程，会忽略非单词组成部分特殊字符；特殊字符为 数字、字母、下划线）
    #           如，'mill_ lane' 会被拆分成 ['mill_','lane']
    #           如，'mill_    lane' 会被拆分成 ['mill_','lane']
    #           如，'mill [] lane' 会被拆分成 ['mill','lane']
    #           如，'mill , lane' 会被拆分成 ['mill','lane']
    # 然后在待搜索的单词序( word_list )列中查看是否存在m,n ，使得 word_list[m:n] == search_list
    # 返回特定字段包含特定短语的文档1。如下，就是返回 address 字段包含短语 'mill' 的文档
    {
        "query":{ "match":{ "address":"mill" } }
    }
    # 返回特定字段包含特定短语的文档2。如下，就是返回 address 字段包含短语 'mill' 或者短语 'lane' 的文档
    {
        "query":{ "match":{ "address":"mill lane" } }
    }
    # 返回特定字段包含特定短语的文档3。如下，就是返回 address 字段包含短语 'mill lane' 的文档
    {
        "query":{ "match_phrase":{ "address":"mill lane" } }
    }
    ```
* 查询语言进阶2 - boolean query
    * 通过boolean query可以将简单的查询条件进行逻辑运算
    * boolean query 的关键字有三个
        * must      (and)     满足所有条件的文档才会被返回
        * should    (or)      满足某一个条件的文档就会被返回
        * must_not  (not)     不满足所有条件的文档才会被返回
    * 下面是这三个的简单例子
    ```
    # fit match1 and fit match2
    {
        "query":{
            "bool":{
                "must":[
                    {"match":{ "address":"mill" }},
                    {"match":{ "address":"lane" }},
                ]
            }
        }
    }
    # fit match1 or fit match2
    {
        "query":{
            "bool":{
                "should":[
                    {"match":{ "address":"mill" }},
                    {"match":{ "address":"lane" }},
                ]
            }
        }
    }
    # (not fit match1) and (not fit match2)
    {
        "query":{
            "bool":{
                "must_not":[
                    {"match":{ "address":"mill" }},
                    {"match":{ "address":"lane" }},
                ]
            }
        }
    }
    ```
    * 同时，在一次查询中，也可以同时使用这三个关键字
    ```
    # age为40 ，且 state 中不包含短语 ID 的文档将会被返回
    {
        "query": {
            "bool": {
                "must": [
                    { "match": { "age": "40" } }
                ],
                "must_not": [
                    { "match": { "state": "ID" } }
                ]
            }
        }
    }
    ```
* 查询语言进阶3 - range query
    * 关键字：
